{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChuchoDC/shape_red/blob/main/ShapeRed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ShapeRed\n",
        "\n",
        "A continuación, se muestra de manera interactiva como ejecutar el programa adecuadamente.\n",
        "\n",
        "Primero, es necesario cambiar el entorno de ejecución, ya que por defecto se utiliza CPU, lo cual hará que el código tarde más tiempo en ejecutarse, esto se puede realizar como se muestra en la imagen, donde vamos a seleccionar un entorno con GPU. \n",
        "\n",
        "![ManualGPU](../images/ManualGPU.png)\n",
        "\n",
        "Una vez cambiado el entorno, vamos a ejecutar la celda que se encuentra debajo, esto hará que el programa se conecte con google drive y pueda realizar la lectura y escritura de archivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAjfVLs-hq-8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yitSxh9H-fZa"
      },
      "source": [
        "En la siguiente celda unicamente se realiza la importación de las librerias necesarias para el funcionamiento del programa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf-7c80d-ek8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, se define una función necesaria para cargar los datos que se van a utilizar para el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZemToB0-oU-"
      },
      "outputs": [],
      "source": [
        "def cargar_datos(csv_file, images_folder, img_size):\n",
        "    datos = pd.read_csv(csv_file)\n",
        "    imagenes = []\n",
        "    landmarks = []\n",
        "\n",
        "    for _, row in datos.iterrows():\n",
        "        img_path = os.path.join(images_folder, row['id'])\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f'Advertencia: No se pudo cargar la imagen {row[\"id\"]}.')\n",
        "            continue\n",
        "\n",
        "        original_size = (img.shape[1], img.shape[0])\n",
        "        img_resized = cv2.resize(img, img_size, interpolation=cv2.INTER_AREA)\n",
        "        img_normalized = img_resized / 255.0\n",
        "        imagenes.append(img_normalized)\n",
        "\n",
        "        coords = row[1:].values.astype(np.float32)\n",
        "        coords[::2] /= original_size[0]\n",
        "        coords[1::2] /= original_size[1]\n",
        "        landmarks.append(coords)\n",
        "\n",
        "    return np.array(imagenes), np.array(landmarks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En el siguiente bloque es necesario modificar el valor de `csv_file` además de `images_folder`, para esto, es necesario copiar la ruta tanto de nuestro archivo **csv** como de la carpeta con las imagenes asociadas.\n",
        "\n",
        "Para esto, es necesario seleccionar la carpeta `Archivos` $\\rightarrow$ `drive` $\\rightarrow$ `MyDrive` y buscar tanto la carpeta como el csv, copiar la ruta de acceso y pegarla en donde se indica.\n",
        "\n",
        "![Manual02](../images/Manual02.PNG)\n",
        "\n",
        "Ya que tenemos la ruta de los archivos se ejecuta la siguiente celda, en caso de que no tengamos la misma cantidad de imágenes y landmarks el programa va a mostrar una advertencia, si es el caso es necesario revisar que los archivos sean correctos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-QmaAkE-rSt"
      },
      "outputs": [],
      "source": [
        "imagenes, landmarks = cargar_datos(\n",
        "    csv_file = 'Archivo_csv',    # Aquí se coloca la ruta del archivo csv\n",
        "    images_folder = 'DirectorioDeImagenes',    # Aquí se coloca la ruta de la carpeta con imagenes\n",
        "    img_size = (100, 100)\n",
        ")\n",
        "if imagenes.shape[0] != landmarks.shape[0]:\n",
        "  print(\"Advertencia, no hay el mismo número de Landmarks e imágenes\")\n",
        "\n",
        "print(f\"Imágenes cargadas: {imagenes.shape}\")\n",
        "print(f\"Landmarks cargados: {landmarks.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En la siguiente celda, se define la arquitectura del modelo que se utiliza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ahSeqORCHOM"
      },
      "outputs": [],
      "source": [
        "def modelo(input_shape, num_landmarks):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (7, 7), activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(64, (5, 5), activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Conv2D(256, (2, 2), activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_landmarks * 2, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, es necesario colocar el número de landmarks con el que estamos trabajando. Además, es en la siguiente celda donde se va a comenzar el entrenamiento, por lo que puede tardar cierto tiempo en ejecutarse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j3Tbu5GCIzm"
      },
      "outputs": [],
      "source": [
        "img_size = (100, 100)\n",
        "input_shape = (img_size[0], img_size[1], 3)\n",
        "num_landmarks = 0          # Colocar el número de landmarks con los que se cuenta\n",
        "\n",
        "modelo = modelo(input_shape, num_landmarks)\n",
        "modelo.compile(optimizer = Nadam(learning_rate=0.0005), loss=\"mae\")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7)\n",
        "historial = modelo.fit(imagenes, landmarks, epochs=120, batch_size=4, validation_split=0.25, callbacks=[reduce_lr])\n",
        "\n",
        "modelo.save('modeloPropuesto.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez realizado el entrenamiento, se va a ejecutar la siguiente celda, la cual va a definir una función para la predicción de landmarks en imágenes nuevas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ogO06o5ChYn"
      },
      "outputs": [],
      "source": [
        "def predecir_landmarks(modelo, imagenes, output_csv, img_size=(100, 100)):\n",
        "    predicciones = []\n",
        "\n",
        "    for img_name in os.listdir(imagenes):\n",
        "        img_path = os.path.join(imagenes, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f'Advertencia: No se pudo cargar la imagen {img_name}.')\n",
        "            continue\n",
        "\n",
        "        original_size = (img.shape[1], img.shape[0])\n",
        "        img = cv2.resize(img, img_size, interpolation=cv2.INTER_AREA)\n",
        "        img = img / 255.0\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        pred = modelo.predict(img, verbose=0)[0]\n",
        "\n",
        "        pred[::2] *= original_size[0]\n",
        "        pred[1::2] *= original_size[1]\n",
        "\n",
        "        predicciones.append([img_name] + pred.tolist())\n",
        "\n",
        "    columnas = ['id'] + [f'X{i}' for i in range(len(pred) // 2)] + [f'Y{i}' for i in range(len(pred) // 2)]\n",
        "    resultados = pd.DataFrame(predicciones, columns=columnas)\n",
        "    resultados.to_csv(output_csv, index=False)\n",
        "    print(f'Resultados guardados en {output_csv}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por último, tal como se hizo al inicio, es necesario copiar la ruta de la carpeta con las imágenes nuevas y colocarla para que el programa se encarge de la predicción de los landmarks, aquí se va a generar un archivo nuevo el cual contenga las coordenadas para las imágenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy6tl_WACkVj"
      },
      "outputs": [],
      "source": [
        "carpeta_imagenes = 'Imagenes Nuevas'\n",
        "output_csv = 'CNN.csv'\n",
        "\n",
        "modelo = load_model('modeloPropuesto.h5', custom_objects={'mae': MeanAbsoluteError()})\n",
        "predecir_landmarks(modelo, carpeta_imagenes, output_csv)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPNoQc6lcQNvZeW2b5OjjOd",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
